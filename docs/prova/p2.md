# Questão 1 – Ao estudarmos o Caminho de Dados, módulos digitais básicos foram integrados para criar o núcleo de um sistema computacional, núcleo capaz de executar instruções lidas a partir da memória. Sobre o Caminho de Dados, responda:


### a) Descreva o modelo uniciclo.

No modelo uniciclo, cada instrução percorre todas as fases (buscar, decodificar, executar, acessar memória e escrever resultado) em um único ciclo de clock, o que simplifica o hardware, mas obriga o clock a ser tão lento quanto a instrução mais demorada.

### b) Descreva o modelo multiciclo, deixando claro em sua resposta as etapas utilizadas para garantir a execução de uma instrução.

No modelo multiciclo, cada instrução é dividida em vários ciclos de clock, reutilizando o mesmo hardware em etapas diferentes. As cinco etapas são: busca da instrução na memória (Fetch), decodificação e leitura de registradores (Decode), execução ou cálculo de endereço (Execute), acesso à memória (Memory) e escrita do resultado no registrador de destino (Writeback).

### c) O Pipeline é uma evolução aplicada ao modelo multiciclo. Como esse arranjo melhora o desempenho computacional da arquitetura multiciclo?

No pipeline, essas mesmas cinco etapas são organizadas em estágios que funcionam em paralelo, permitindo que várias instruções sejam processadas ao mesmo tempo (uma em Fetch, outra em Decode, outra em Execute, etc.). Depois de cheio, o pipeline se aproxima de completar uma instrução por ciclo, reduzindo o CPI em relação aos modelos uniciclo e multiciclo sem pipeline.

### d) No modelo multiciclo, qual é a quantidade de ciclos máxima (teórica) necessária para executar uma instrução? Por que, na prática, as instruções executam gastando uma quantidade diferente de ciclos do que aquela que foi prevista no modelo teórico? Cite exemplos de instruções em que a quantidade teórica é diferente da observada na prática, indicando os motivos pelos quais isso acontece.

No modelo multiciclo, o máximo teórico é 5 ciclos por instrução. Na prática, as instruções gastam quantidades diferentes de ciclos porque nem todas precisam passar por todas as etapas. Por exemplo, `lw` usa 5 ciclos (IF, ID, EX, MEM, WB), `sw` não faz Writeback e usa 4 ciclos, `beq` não acessa memória nem escreve registrador e usa cerca de 3 ciclos, e instruções do tipo R, como `add`, usam menos etapas do que `lw`, consumindo menos ciclos.

---

# Questão 2 – Considerando sistemas computacionais, responda:

### a) O que é um barramento? Na sua resposta, indique também os conjuntos de linhas tipicamente encontrados em um barramento.

Um barramento é um conjunto de linhas condutoras compartilhadas que interliga CPU, memória e dispositivos de E/S, permitindo a troca de informações. Ele é formado, tipicamente, por linhas de endereço (indicam onde ler ou escrever), linhas de dados (transportam os valores), linhas de controle (definem o tipo de operação e o dispositivo ativo) e linhas de potência (alimentação). Barramentos paralelos transmitem vários bits ao mesmo tempo em muitas linhas, enquanto barramentos seriais transmitem os bits em poucas linhas, um por vez, compensando com frequências maiores e técnicas de codificação e correção de erros.

### b) O que é uma exceção no contexto de um sistema computacional? Como um processador digital lida/trata uma exceção? Na sua resposta, cite exemplos de exceções.

Uma exceção é um desvio anormal do fluxo normal de execução causado por um evento interno, como instrução ilegal, endereço desalinhado ou falha de acesso à memória. Ao detectar a exceção, o processador interrompe o programa, salva o contexto essencial (por exemplo, o endereço da instrução que causou o problema), desvia para uma rotina de tratamento (exception handler), executa a ação apropriada (corrigir, abortar, sinalizar erro) e depois pode retornar ao programa. Exemplos incluem instrução ilegal, endereço de instrução desalinhado e endereço de load/store desalinhado.

### c) Por que uma quantidade pequena de memória de elevada velocidade (SRAM) é capaz de prover um desempenho computacional elevado para um sistema que explora hierarquia de memórias?

Uma pequena quantidade de SRAM rápida, usada como cache, melhora o desempenho porque os programas tendem a reutilizar, muitas vezes, um conjunto pequeno de instruções e dados, e a acessar posições vizinhas na memória. Esses dados mais usados ficam na SRAM e são acessados em poucos ciclos, enquanto apenas uma parte menor dos acessos vai para a DRAM mais lenta. Como o desempenho efetivo depende do tempo médio de acesso (AMAT) — que combina tempo de acerto + taxa de faltas × penalidade da falta — ter uma cache SRAM pequena, porém com alta taxa de acertos, faz o tempo médio ficar próximo ao da SRAM, mesmo que o restante da hierarquia (DRAM, SSD, HDD) seja muito maior e mais lenta.
